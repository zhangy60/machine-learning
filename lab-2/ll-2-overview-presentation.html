<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Machine Learning Learning Lab 2: Feature Engineering</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Joshua Rosenberg" />
    <meta name="date" content="2022-07-12" />
    <script src="libs/header-attrs-2.14/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"<i class=\"fa fa-clipboard\"><\/i>","success":"<i class=\"fa fa-check\" style=\"color: #90BE6D\"><\/i>","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <link rel="stylesheet" href="css/laser.css" type="text/css" />
    <link rel="stylesheet" href="css/laser-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: clear, title-slide, inverse, center, top, middle











# Machine Learning Learning Lab 2: Feature Engineering
----
### **Dr. Joshua Rosenberg**
### July 12, 2022

---

# Background

- In the last learning lab, we did a nice job of training a model that was _pretty good_
- But, can we do better?
- This question motivates this learning lab, specifically:
    - Answering it
    - And, developing a _means_ to answer it in a way that does not introduce bias into our analysis
- Feature engineering is a key way we can improve our model
- Feature engineering refers to the part of machine learning wherein we decide which variables to include in which forms

---

# Agenda

.pull-left[
## Part 1: Core Concepts
### Feature engineering
- Selecting and preparing variables for inclusion as features
- k-folds cross-validation
]

.pull-right[

## Part 2: R Code Examples
### Online science classes
- Daa from online science classes
- Interpreting changes in fit measures
]

---

class: clear, inverse, center, middle

# Core Concepts

---

# Why feature engineering matters

- Let's consider a very simple data set, one with _time series_ (or longitudinal) data for a single student




```
## # A tibble: 10 × 3
##    student_id time_point var_a
##    &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt;
##  1 janyia              1  0.01
##  2 janyia              2  0.32
##  3 janyia              3  0.32
##  4 janyia              4  0.34
##  5 janyia              5  0.04
##  6 janyia              6  0.54
##  7 janyia              7  0.56
##  8 janyia              8  0.75
##  9 janyia              9  0.63
## 10 janyia             10  0.78
```

- **How can we include a variable, `var_a`, in a machine learning model?**

---

# How can we include a single variable?

Let's take a look at the variable

![](ll-2-overview-presentation_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;

---

# How can we include a single variables

- Well, what if we just add the values for these variables directly
- But, that ignores that they are at different time points
    - We could include the time point variable, but that is (about) the same for every student

*What are some other ideas?*

---

# A few (other) options

- Raw data points
- Their mean
- Their maximum
- Their variability (standard deviation)
- Their linear slope
- Their quadratic slope

**Each of these may derive from a single _variable_ but may offer predictive utility as distinct _features_**

---

# Let's consider one more example

Here's a time stamp:


```
## [1] "2022-07-12 09:27:51 EDT"
```

**How could this variable be used as a predictor variable?**

---

# Discussion

.pull-left[
### Turn to an elbow partner and discuss:

- What _variables_ might you use in your use of ML?
- What _features_ could be created from these variables?
- What is unclear or about what do you have a question (so far)?
]

.pull-right[

&lt;img src="img/joro-cycle.jpeg" width="75%" /&gt;

]

---

# What else should we consider?

## For all variables

- Removing those with "near-zero variance"
- Removing ID variables and others that _should not be_ informative
- Imputing missing values
- Extract particular elements (i.e., particular _days_ or _times_) from time-related data 

## For specific types of variables

- Categorical variables
    - Combining categories
- Numeric variables
    - Normalizing ("standardizing")

---

# How to do this?

- We can do all of these things manually
- But, there are also helpful functions to do this
- Any, the {recipes} package makes it practical to carry out feature engineering steps for not only single variables, but groups of variables (or all of the variables)
- Examples, all of which start with `_step()`:
    - `step_dummy()`
    - `step_normalize()`
    - `step_nzv()`
    - `step_impute_knn()`

*We'll dive in deeper in the code examples*

---

# The importance of training data

- Training data is what we use to "learn" from data
- A "check" on your work is your predictions on _test_ set data
  - *Train data*: Outcome data that you use to fit your model
  - *Validation data&lt;sup&gt;1&lt;/sup&gt;*: Data you use to select a particular algorithm
  - *Test ("hold-out") data*: Data that you do not use in any way to train your model

.footnote[
[1] not always/often used in practice, for reasons we'll discuss momentarily
]

---

# The problem introduced by feature engineering

In LL1, we fit and interpreted a single model; let's think carefully through how we "spent" our training and testing data in that lab

--

*Training data*: Used this set (80%) of the data to train our model
*Testing data*: Evaluated the performance of the model using this set (20%) of the data

--

What if we decided to _add new features_ or _change existing features_?

We'd need to use the same training data to tune a new model---and the same testing data to evaluate its performance

--

**But, doing this could lead us to specifying a model based on how well we predict the data that happened to end up in the testing set. We could be optimizing our model for our testing data; when used with new data, that model could do poorly.**

---

# The problem introduced by feature engineering

- In short, a challenges arises when we wish to use our training data _more than once_
- Namely, if we repeatedly training an algorithm on the same data and then make changes, we may be tailoring our model to specific features of the testing data
- This is a _very common and pervasive problem_ in machine learning applications
- Resampling conserves our testing data; we don't have to spend it until we've finalized our model

---

# Resampling (and _k_-folds cross-validation)

- Resampling involves blurring the boundaries between training and testing data, _but only for the training split of the data_
- Specifically, it involves combining these two portions of our data into one, iteratively considering:
    - Some of the data to be for "training"
    - Some for "testing"
- Then, fit measures are summed across these different samples

---

# *k*-folds cross validation

- One of the most common and useful forms of resampling is *k*-folds cross validation
    - Here, some of the data is considered to be a part of the *training* set 
    - The remaining data is a part of the *testing* set

- How many sets (samples taken through resampling)?
    - This is determined by _k_, number of times the data is resampled
    - When _k_ is equivalent to the number of rows in the data, this is often called "Leave One Out Cross-Validation" (LOOCV)
---

# Let's consider an example

Say we have a data set, `d`, with 100 observations (rows or data points) with _k_ = 10.




```
## # A tibble: 100 × 3
##       id  var_a  var_b
##    &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1     1 0.375  0.0263
##  2     2 0.156  0.267 
##  3     3 0.204  0.172 
##  4     4 0.104  0.238 
##  5     5 0.0806 0.760 
##  6     6 0.539  0.426 
##  7     7 0.701  0.985 
##  8     8 0.237  0.406 
##  9     9 0.216  0.159 
## 10    10 0.865  0.0728
## # … with 90 more rows
```

**Using _k_ = 10, how can we split this data into ten distinct training and testing sets?**

---

# First resampling


```
## # A tibble: 3 × 3
##      id var_a  var_b
##   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     1 0.375 0.0263
## 2     2 0.156 0.267 
## 3     3 0.204 0.172
```

```
## # A tibble: 3 × 3
##      id var_a var_b
##   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    91 0.538 0.226
## 2    92 0.839 0.862
## 3    93 0.396 0.295
```

---

# Second resampling


```
## # A tibble: 3 × 3
##      id var_a  var_b
##   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     1 0.375 0.0263
## 2     2 0.156 0.267 
## 3     3 0.204 0.172
```

```
## # A tibble: 3 × 3
##      id var_a var_b
##   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    81 0.491 0.455
## 2    82 0.299 0.601
## 3    83 0.818 0.702
```

---

# Third resampling


```
## # A tibble: 3 × 3
##      id var_a  var_b
##   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     1 0.375 0.0263
## 2     2 0.156 0.267 
## 3     3 0.204 0.172
```

```
## # A tibble: 3 × 3
##      id var_a  var_b
##   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1    71 0.441 0.0448
## 2    72 0.929 0.266 
## 3    73 0.402 0.381
```

... through the tenth resampling, after which the fit measures are simply summed

That's it! Thankfully, we have automated tools to do this that we'll work on in the code examples

---

# But how do you determine what _k_ should be?

- A _historically common value_ for _k_ has been 10
- But, as computers have grown in processing power, setting _k_ equal to the number of rows in the data has become more common

---

class: clear, inverse, center, middle

# Code Examples

---

# Data from online science classes

- This data comes from a study of ~700 secondary/high school-aged students in the United States
- The data were collected _over multiple semesters_ from _multiple classes_
- There are a number of types of variables


.panelset[
.panel[.panel-name[1]

 - Demographic/contextual variables, e.g. `subject` and `gender`

]

.panel[.panel-name[2]

  - Self-report survey variables: `uv` (utility value), `percomp` (perceived competence), and `int` (interest)
  
]

.panel[.panel-name[3]

  - Gradebook variables: `overall_percent_earned`, `variability_percent_earned`, `n_with_100_pct` (based on the first 20 assignments)

]

.panel[.panel-name[4]

  - Discussion variables: `sum_discussion_posts`, `sum_n_words` (for the first 3 discussions)

]

.panel[.panel-name[5]

  - Outcomes: `final_grade`, `passing_grade`, `time_spent` (in minutes)

]
]

---

# Sidebar

This data is described further (and descriptively and inferentially analyzed using a regression and multi-level modeling approach) in *Data Science in Education Using R*:

- Chapter 7: The Education Data Science Pipeline With Online Science Class Data: https://datascienceineducation.com/c07.html

- Chapter 13: The Role (and Usefulness) of Multilevel Models: https://datascienceineducation.com/c13.html

- Chapter 14: Predicting Students’ Final Grades Using Machine Learning Methods with Online Course Data: https://datascienceineducation.com/c14.html

---

# Let's take a look at the data together


```
## Rows: 546
## Columns: 15
## $ student_id           &lt;dbl&gt; 60186, 66693, 66811, 70532, 77010, 85249, 85411, …
## $ course_id            &lt;chr&gt; "AnPhA-S116-01", "AnPhA-S116-01", "AnPhA-S116-01"…
## $ gender               &lt;chr&gt; "M", "M", "F", "F", "F", "F", "F", "F", "F", "F",…
## $ enrollment_reason    &lt;chr&gt; "Course Unavailable at Local School", "Course Una…
## $ enrollment_status    &lt;chr&gt; "Approved/Enrolled", "Approved/Enrolled", "Approv…
## $ final_grade          &lt;dbl&gt; 86.27200, 93.75360, 91.20160, 93.64000, 73.17067,…
## $ subject              &lt;chr&gt; "AnPhA", "AnPhA", "AnPhA", "AnPhA", "AnPhA", "AnP…
## $ semester             &lt;chr&gt; "S116", "S116", "S116", "S116", "S116", "S116", "…
## $ section              &lt;chr&gt; "01", "01", "01", "01", "01", "01", "01", "01", "…
## $ int                  &lt;dbl&gt; 4.2, 5.0, 4.0, 4.6, NA, 4.0, 4.4, 5.0, 5.0, 4.2, …
## $ uv                   &lt;dbl&gt; 4.333333, 5.000000, 4.000000, 4.666667, 3.666667,…
## $ percomp              &lt;dbl&gt; 4.5, 5.0, NA, 4.0, 3.5, 4.5, 3.5, 3.5, 4.0, 3.5, …
## $ percentage_earned    &lt;dbl&gt; 0.9602941, 0.9764706, 0.9452353, 0.9485294, 0.737…
## $ sum_discussion_posts &lt;dbl&gt; 9, 6, 9, 11, 9, 9, 12, 8, 7, 9, 9, 9, NA, 12, 9, …
## $ sum_n_words          &lt;dbl&gt; 939, 311, 474, 578, 496, 284, 452, 382, 138, 239,…
```

---

class: clear, inverse, center, middle

# Code Examples

*Note how these steps are the same as in the classification example for LL 1*

---

# Let's walk through a few steps

.panelset[

.panel[.panel-name[0]

**Prepare**


```r
library(tidyverse)
library(tidymodels)

d &lt;- read_csv("data/online-sci-data-joined.csv")
```

]

.panel[.panel-name[1]

**Split data**


```r
set.seed(20220712)

train_test_split &lt;- initial_split(d, prop = .80)

data_train &lt;- training(train_test_split)

kfcv &lt;- vfold_cv(data_train, v = 15) # this differentiates this from what we did before
# before, we simple used data_train to fit our model
```
]

.panel[.panel-name[2]

**Engineer features**


```r
my_rec &lt;- recipe(final_grade ~ ., data = d) %&gt;% # a continuous measure of students' final grade
    step_normalize(all_numeric_predictors()) %&gt;% # standardizes numeric variables
    step_nzv(all_predictors()) %&gt;% # remove predictors with a "near-zero variance"
    step_novel(all_nominal_predictors()) %&gt;% # add a musing label for factors
    step_dummy(all_nominal_predictors()) %&gt;%  # dummy code all factor variables
    step_impute_knn(all_predictors()) # impute missing data for all predictor variables
```
]

.panel[.panel-name[3]

**Specify the model and workflow**
 

```r
my_mod &lt;-
    linear_reg() %&gt;% # note the difference here
    set_engine("glm") %&gt;% 
    set_mode("regression") # and here

# specify workflow
my_wf &lt;-
    workflow() %&gt;%
    add_model(my_mod) %&gt;% 
    add_recipe(my_rec)
```
]

.panel[.panel-name[4]

**Fit model**


```r
fitted_model &lt;- fit_resamples(my_wf, resamples = kfcv,
                              control = control_grid(save_pred = TRUE)) # this allows us to inspect the predictions
```
]

.panel[.panel-name[5]

**Evaluate accuracy**


```r
fitted_model %&gt;% 
    unnest(.metrics) %&gt;% 
    filter(.metric == "rmse") # we also get another metric, the ROC; we focus just on accuracy for now
```
]
]

---

# What's next?

- **Case study**: You'll run all of this code, focusing on feature engineering and working with resamples
- **Independent practice**: In the independent practice, you'll focus on adding a new (not yet used!) feature engineering step

---

class: clear, center

## .font130[.center[**Thank you!**]]

&lt;br/&gt;
.center[&lt;img style="border-radius: 80%;" src="img/jr-cycling.jpeg" height="200px"/&gt;&lt;br/&gt;**Dr. Joshua Rosenberg**&lt;br/&gt;&lt;mailto:jmrosenberg@utk.edu&gt;]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "default",
"highlightLines": true,
"highlightLanguage": "r",
"countIncrementalSlides": false,
"ratio": "16:9",
"slideNumberFormat": "<div class=\"progress-bar-container\">\n <div class=\"progress-bar\" style=\"width: calc(%current% / %total% * 100%);\">\n </div>\n</div>"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
